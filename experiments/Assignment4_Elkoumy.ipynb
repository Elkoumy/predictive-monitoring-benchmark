{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 4 : Predictive Process Monitoring</center>\n",
    "\n",
    "## <center>Gamal Elkoumy</center>\n",
    "### <center>University of Tartu, 2021</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we report the our solution to the predictive process monitoring presented here https://courses.cs.ut.ee/LTAT.05.025/2021_spring/uploads/Main/2021Homework4.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution GitHub Repository\n",
    "Our solution is available using the following URL.\n",
    "https://github.com/Elkoumy/predictive-monitoring-benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "(1 point) \n",
    "\n",
    "As part of the log preprocessing, it is necessary to categorize the process traces as\n",
    "deviant or regular. This log contains a column called SLA. it is a \"case attribute,\" which indicates\n",
    "how many minutes each case must complete. You must create a new column in the log that\n",
    "contains a case attribute called label, which contains a value of 1 for deviant cases or 0 for\n",
    "regular ones. This column's value is 0 if the duration of the case (in minutes) is less than or equal\n",
    "to the SLA; otherwise, this column's value must be 1 (the SLA has not been met). NB! If there are\n",
    "cases that do not have SLA, categorize them as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EncoderFactory\n",
    "from DatasetManager import DatasetManager\n",
    "import BucketFactory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "import os\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Gamal Elkoumy\\PhD\\OneDrive - Tartu Ülikool\\Courses\\Process Mining\\Assignment4\\predictive-monitoring-benchmark\\data\\turnaround_anon_sla.csv')\n",
    "\n",
    "#converting datatypes , timestamps\n",
    "df.start_timestamp= pd.to_datetime(df.start_timestamp,utc=True)\n",
    "df.end_timestamp= pd.to_datetime(df.end_timestamp,utc=True)\n",
    "\n",
    "df=df.sort_values(['start_timestamp']).reset_index()\n",
    "df=df.drop('index',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1\"\"\"\n",
    "\n",
    "#calculating the start time and end time of every case\n",
    "df['case_end_time']=df.groupby(['caseid']).end_timestamp.transform('max')\n",
    "df['case_start_time']=df.groupby(['caseid']).start_timestamp.transform('min')\n",
    "\n",
    "#calculating case duration in minutes ( the same time unit as the SLA)\n",
    "df['duration']=(df.case_end_time-df.case_start_time).astype('timedelta64[m]')\n",
    "\n",
    "\n",
    "#creating the label column\n",
    "df['label']=1\n",
    "df.loc[df.duration<=df['SLA MIN'],'label']=0\n",
    "df.loc[df['SLA MIN'].isna(),'label']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "(2 points) \n",
    "\n",
    "Add a column to the event log that captures the WIP of the process at the moment\n",
    "where the last eventin the prefix occurs. Remember that the WIP refers to the number of active\n",
    "cases, meaning the number of cases that have started but not yet completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we define a funtion that performs the estimation of wip for each activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_wip(row, case_times):\n",
    "    wip=0\n",
    "    #started before start and ended after end\n",
    "    #started after start and ended before end\n",
    "    #started before start and ended before end\n",
    "    #started before end and ended after end\n",
    "    wip=case_times.loc[(case_times.case_start_time<= row.start_timestamp) & (case_times.case_end_time>=row.end_timestamp) |\n",
    "                       (case_times.case_start_time >= row.start_timestamp) & (case_times.case_end_time <= row.end_timestamp)|\n",
    "                       (case_times.case_start_time <= row.start_timestamp) & (case_times.case_end_time >= row.start_timestamp)|\n",
    "                       (case_times.case_start_time <= row.end_timestamp) & (case_times.case_end_time >= row.end_timestamp)\n",
    "                       ].shape[0]\n",
    "\n",
    "    return wip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then use the pandas apply function to execute the count_wip function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2\"\"\"\n",
    "case_times= pd.DataFrame()\n",
    "case_times['case_end_time']=df.groupby(['caseid']).end_timestamp.max()\n",
    "case_times['case_start_time']=df.groupby(['caseid']).start_timestamp.min()\n",
    "case_times=case_times.reset_index()\n",
    "\n",
    "df['WIP']=df.apply(count_wip,case_times=case_times ,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We export the result in order to use it separately to optimize the model parameters as we will mention later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'caseid': 'Case ID','activity':'Activity', 'start_timestamp':'time:timestamp'})\n",
    "df.to_csv(r'C:\\Gamal Elkoumy\\PhD\\OneDrive - Tartu Ülikool\\Courses\\Process Mining\\Assignment4\\predictive-monitoring-benchmark\\experiments\\experiment_log\\turnaround_anon_sla_renamed.csv',index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a preprocessing for the next step, we prepare the data for the train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = \"turnaround_anon_sla_renamed\"\n",
    "params_dir = \"optimizer_log\"\n",
    "results_dir = \"experiment_log\"\n",
    "bucket_method = \"cluster\"\n",
    "cls_encoding = \"index\"\n",
    "cls_method = \"xgboost\"\n",
    "ngram_size = 4\n",
    "bucket_encoding = \"agg\"\n",
    "method_name = \"%s_%s\" % (bucket_method, cls_encoding)\n",
    "\n",
    "encoding_dict = {\n",
    "    \"laststate\": [\"static\", \"last\"],\n",
    "    \"agg\": [\"static\", \"agg\"],\n",
    "    \"index\": [\"static\", \"index\"],\n",
    "    \"combined\": [\"static\", \"last\", \"agg\"]\n",
    "}\n",
    "\n",
    "methods = encoding_dict[cls_encoding]\n",
    "\n",
    "train_ratio = 0.8\n",
    "random_state = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results directory\n",
    "if not os.path.exists(os.path.join(params_dir)):\n",
    "    os.makedirs(os.path.join(params_dir))\n",
    "\n",
    "dataset_name=dataset_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use the DataManager class in order to perform the train/testsplit. We adapted the code to fit the current event log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Case ID', 'Activity', 'time:timestamp', 'end_timestamp', 'SLA MIN',\n",
      "       'case_end_time', 'case_start_time', 'duration', 'label', 'WIP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Split into train and test\"\"\"\n",
    "# read the data\n",
    "dataset_manager = DatasetManager(dataset_name)\n",
    "data = dataset_manager.read_dataset()\n",
    "cls_encoder_args = {'case_id_col': dataset_manager.case_id_col,\n",
    "                    'static_cat_cols': dataset_manager.static_cat_cols,\n",
    "                    'static_num_cols': dataset_manager.static_num_cols,\n",
    "                    'dynamic_cat_cols': dataset_manager.dynamic_cat_cols,\n",
    "                    'dynamic_num_cols': dataset_manager.dynamic_num_cols,\n",
    "                    'fillna': True}\n",
    "\n",
    "\n",
    "# split into training and test\n",
    "train, test = dataset_manager.split_data_strict(data, train_ratio, split=\"temporal\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "(4 points) \n",
    "\n",
    "Currently, the work proposed by Taineema et al. performs the extraction of the prefixes\n",
    "of the traces registered in the log to train the classification models. For large logs, this approach\n",
    "leads to an increase in the dimensionality of the models' input (too many features) without\n",
    "necessarily improving its precision, especially in cases in which the event traces are very long.\n",
    "You must modify this technique to extract subsequences of size n (n-grams), where n is a userdefined parameter, instead of encoding entire prefixes. An n-gram is a contiguous sequence of n\n",
    "items from a given trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we define the function that calculates the n-grams. The following function calculates the prefixes using the n-grams for every case separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(data, ngram_size):\n",
    "    result=pd.DataFrame()\n",
    "\n",
    "\n",
    "    for idx in range(0,data.shape[0]- ngram_size +1):\n",
    "\n",
    "        prefix=data.iloc[idx:idx+ngram_size].copy()\n",
    "        prefix=prefix.reset_index()\n",
    "\n",
    "        prefix['Case ID']=prefix['Case ID']+'_'+str(idx)\n",
    "        prefix['prefix_nr'] = idx + 1\n",
    "        result=pd.concat([result,prefix])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We modified the function generate_prefix_data inside the DatasetManager class in order to apply the ngrams. The new function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prefix_data(self,data, ngram_size):\n",
    "    # generate prefix data (each possible prefix becomes a trace)\n",
    "\n",
    "    # ngram_size=3\n",
    "    dt_prefixes=data.groupby(['Case ID']).apply(create_ngrams, ngram_size)\n",
    "\n",
    "    dt_prefixes=dt_prefixes.rename(columns={'Case ID': 'newcaseid'})\n",
    "    dt_prefixes=dt_prefixes.reset_index().rename(columns={'Case ID': 'original_caseid'})\n",
    "    dt_prefixes=dt_prefixes.drop('level_1',axis=1)\n",
    "    dt_prefixes=dt_prefixes.rename(columns={'newcaseid': 'Case ID'})\n",
    "\n",
    "    return dt_prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test prefixes\n",
    "dt_test_prefixes = dataset_manager.generate_prefix_data(test, ngram_size)\n",
    "# for train prefixes\n",
    "dt_train_prefixes = dataset_manager.generate_prefix_data(train, ngram_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "(3 points) \n",
    "\n",
    "Test the results of your modifications with the Turnaround process event log using\n",
    "cluster bucketing, index encoding, and the XGboost model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization\n",
    "\n",
    "Taineema et al provide a method for optimizing the model parameters for predictive process monitoring. The file <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/optimize_params.py\">optimize_params.py</a> performs the parameter optimization. We adopted the file by adding the required parameters for the input event log \"turnaround_anon_sla.csv\".\n",
    "\n",
    "We needed also to perform adaptations in the file <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/dataset_confs.py\">dataset_confs.py</a> in order to enable the parameter tuning for the dataset \"turnaround_anon_sla.csv\". \n",
    "\n",
    "We used the following command to execute the optimizer:\n",
    " python optimize_params.py turnaround_anon_sla_renamed optimizer_log 10  cluster index xgboost \n",
    "\n",
    "The output of the optimizer could be found in the folder <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/optimizer_log\">optimizer_log</a>. Also, the optimial parameters are in the pickle file <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/optimizer_log/optimal_params_xgboost_turnaround_anon_sla_renamed_cluster_index.pickle\">optimal_params_xgboost_turnaround_anon_sla_renamed_cluster_index.pickle</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Bucketing\n",
    "\n",
    "Following our adaptation for the \"experiment.py\" file to perform the training with cluster bucketing, index encoding and the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing prefixes based on control flow\n",
    "bucketer_args = {'encoding_method': bucket_encoding,\n",
    "                 'case_id_col': dataset_manager.case_id_col,\n",
    "                 'cat_cols': [dataset_manager.activity_col],\n",
    "                 'num_cols': [],\n",
    "                 'random_state': random_state}\n",
    "\n",
    "\n",
    "# load optimal params\n",
    "optimal_params_filename = os.path.join(params_dir,\n",
    "                                       \"optimal_params_%s_%s_%s.pickle\" % (cls_method, dataset_name, method_name))\n",
    "\n",
    "with open(optimal_params_filename, \"rb\") as fin:\n",
    "    args = pickle.load(fin)\n",
    "\n",
    "if bucket_method == \"cluster\":\n",
    "    bucketer_args[\"n_clusters\"] = int(args[\"n_clusters\"])\n",
    "bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Bucketing for both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n",
    "\n",
    "bucket_assignments_test = bucketer.predict(dt_test_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Caching the results for AUC score\"\"\"\n",
    "\n",
    "preds_all = []\n",
    "test_y_all = []\n",
    "nr_events_all = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over every bucket to perform index encoding and training XGBoost\n",
    "In the following code, we build our data processing pipeline. First we iterate over each buacket. We perform index encoding using the ``EncoderFactory`` class. We then train the classifier for the buacket using XGBoost. The XGBoost parameters are optimized using the \"optimize_params.py\" module, as we have mentioned above. The output of the optimizer could be found in the folder <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/optimizer_log\">```optimizer_log```</a>. Also, the optimial parameters are in the pickle file <a href=\"https://github.com/Elkoumy/predictive-monitoring-benchmark/blob/master/experiments/optimizer_log/optimal_params_xgboost_turnaround_anon_sla_renamed_cluster_index.pickle\">```optimal_params_xgboost_turnaround_anon_sla_renamed_cluster_index.pickle```</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:39:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" ************* Perfroming Index Encoding per bucket******************\"\"\"\n",
    "for bucket in set(bucket_assignments_test):\n",
    "    if bucket_method == \"prefix\":\n",
    "        current_args = args[bucket]\n",
    "    else:\n",
    "        current_args = args\n",
    "    relevant_train_cases_bucket = dataset_manager.get_indexes(dt_train_prefixes)[\n",
    "        bucket_assignments_train == bucket]\n",
    "    relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[\n",
    "        bucket_assignments_test == bucket]\n",
    "    dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n",
    "\n",
    "    nr_events_all.extend(list(dataset_manager.get_prefix_lengths(dt_test_bucket)))\n",
    "    if len(relevant_train_cases_bucket) == 0:\n",
    "        preds = [dataset_manager.get_class_ratio(train)] * len(relevant_test_cases_bucket)\n",
    "\n",
    "    else:\n",
    "        dt_train_bucket = dataset_manager.get_relevant_data_by_indexes(dt_train_prefixes,\n",
    "                                                                       relevant_train_cases_bucket)  # one row per event\n",
    "        train_y = dataset_manager.get_label_numeric(dt_train_bucket)\n",
    "\n",
    "        if len(set(train_y)) < 2:\n",
    "            preds = [train_y[0]] * len(relevant_test_cases_bucket)\n",
    "\n",
    "            test_y_all.extend(dataset_manager.get_label_numeric(dt_test_bucket))\n",
    "        else:\n",
    "\n",
    "            feature_combiner = FeatureUnion(\n",
    "                [(method, EncoderFactory.get_encoder(method, **cls_encoder_args)) for method in methods])\n",
    "\n",
    "\n",
    "            cls = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                    n_estimators=500,\n",
    "                                    learning_rate=current_args['learning_rate'],\n",
    "                                    subsample=current_args['subsample'],\n",
    "                                    max_depth=int(current_args['max_depth']),\n",
    "                                    colsample_bytree=current_args['colsample_bytree'],\n",
    "                                    min_child_weight=int(current_args['min_child_weight']),\n",
    "                                    seed=random_state)\n",
    "\n",
    "            pipeline = Pipeline([('encoder', feature_combiner), ('cls', cls)])\n",
    "\n",
    "            pipeline.fit(dt_train_bucket, train_y)\n",
    "\n",
    "\n",
    "            # predict separately for each prefix case\n",
    "            preds = []\n",
    "            test_all_grouped = dt_test_bucket.groupby(dataset_manager.case_id_col)\n",
    "            for _, group in test_all_grouped:\n",
    "\n",
    "                test_y_all.extend(dataset_manager.get_label_numeric(group))\n",
    "\n",
    "\n",
    "                _ = bucketer.predict(group)\n",
    "\n",
    "                preds_pos_label_idx = np.where(cls.classes_ == 1)[0][0]\n",
    "                pred = pipeline.predict_proba(group)[:, preds_pos_label_idx]\n",
    "\n",
    "\n",
    "                preds.extend(pred)\n",
    "\n",
    "    preds_all.extend(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We evaluate the trained model using the ROC AUC score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC is: 0.9328061413244543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_results = pd.DataFrame({\"actual\": test_y_all, \"predicted\": preds_all, \"nr_events\": nr_events_all})\n",
    "\n",
    "print(\"The AUC is: %s\\n\" % (roc_auc_score(dt_results.actual, dt_results.predicted)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
